{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, data, catCols=None, outputCol=None):      \n",
    "        \"\"\"\n",
    "        Characterizes a Dataset for PyTorch\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        data: pandas data frame\n",
    "          The data frame object for the input data. It must\n",
    "          contain all the continuous, categorical and the\n",
    "          output columns to be used.\n",
    "\n",
    "        catCols: List of strings\n",
    "          The names of the categorical columns in the data.\n",
    "          These columns will be passed through the embedding\n",
    "          layers in the model. These columns must be\n",
    "          label encoded beforehand. \n",
    "\n",
    "        outputCol: string\n",
    "          The name of the output variable column in the data\n",
    "          provided.\n",
    "        \"\"\"\n",
    "        self.n = data.shape[0]\n",
    "    \n",
    "        if outputCol:\n",
    "            self.y = data[outputCol].astype(np.float32).values.reshape(-1, 1)\n",
    "        else:\n",
    "            self.y =  np.zeros((self.n, 1))\n",
    "\n",
    "        self.catCols = catCols if catCols else []\n",
    "        self.contCols = [col for col in data.columns\n",
    "                        if col not in self.catCols + [outputCol]]\n",
    "\n",
    "        if self.contCols:\n",
    "            self.contX = data[self.contCols].astype(np.float32).values\n",
    "        else:\n",
    "            self.contX = np.zeros((self.n, 1))\n",
    "\n",
    "        if self.catCols:\n",
    "            self.catX = data[catCols].astype(np.int64).values\n",
    "        else:\n",
    "            self.catX =  np.zeros((self.n, 1))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Denotes the total number of samples.\n",
    "        \"\"\"\n",
    "        return self.n\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generates one sample of data.\n",
    "        \"\"\"\n",
    "        return [self.y[idx], self.contX[idx], self.catX[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, embDims, noOfCont, linLayerSizes, outputSize, embDropout, linLayerDropouts):\n",
    "\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "\n",
    "        embDims: List of two element tuples\n",
    "          This list will contain a two element tuple for each\n",
    "          categorical feature. The first element of a tuple will\n",
    "          denote the number of unique values of the categorical\n",
    "          feature. The second element will denote the embedding\n",
    "          dimension to be used for that feature.\n",
    "\n",
    "        noOfCont: Integer\n",
    "          The number of continuous features in the data.\n",
    "\n",
    "        linLayerSizes: List of integers.\n",
    "          The size of each linear layer. The length will be equal\n",
    "          to the total number\n",
    "          of linear layers in the network.\n",
    "\n",
    "        outputSize: Integer\n",
    "          The size of the final output.\n",
    "\n",
    "        embDropout: Float\n",
    "          The dropout to be used after the embedding layers.\n",
    "\n",
    "        linLayerDropouts: List of floats\n",
    "          The dropouts to be used after each linear layer.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layers\n",
    "        self.embLayers = nn.ModuleList([nn.Embedding(x, y)\n",
    "                                         for x, y in embDims])\n",
    "\n",
    "        noOfEmbs = sum([y for x, y in embDims])\n",
    "        self.noOfEmbs = noOfEmbs\n",
    "        self.noOfCont = noOfCont\n",
    "\n",
    "        # Linear Layers\n",
    "        firstLinLayer = nn.Linear(self.noOfEmbs + self.noOfCont,\n",
    "                                    linLayerSizes[0])\n",
    "\n",
    "        self.linLayers =\\\n",
    "         nn.ModuleList([firstLinLayer] +\\\n",
    "              [nn.Linear(linLayerSizes[i], linLayerSizes[i + 1])\n",
    "               for i in range(len(linLayerSizes) - 1)])\n",
    "\n",
    "        for linLayer in self.linLayers:\n",
    "            nn.init.kaiming_normal_(linLayer.weight.data)\n",
    "\n",
    "        # Output Layer\n",
    "        self.outputLayer = nn.Linear(linLayerSizes[-1],\n",
    "                                      outputSize)\n",
    "        nn.init.kaiming_normal_(self.outputLayer.weight.data)\n",
    "\n",
    "        # Batch Norm Layers\n",
    "        self.firstBnLayer = nn.BatchNorm1d(self.noOfCont)\n",
    "        self.bnLayers = nn.ModuleList([nn.BatchNorm1d(size)\n",
    "                                        for size in linLayerSizes])\n",
    "\n",
    "        # Dropout Layers\n",
    "        self.embDropoutLayer = nn.Dropout(embDropout)\n",
    "        self.droputLayers = nn.ModuleList([nn.Dropout(size)\n",
    "                                      for size in linLayerDropouts])\n",
    "\n",
    "    def forward(self, contData, catData):\n",
    "\n",
    "        if self.noOfEmbs != 0:\n",
    "            x = [embLayer(catData[:, i]) for i,embLayer in enumerate(self.embLayers)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.embDropoutLayer(x)\n",
    "\n",
    "        if self.noOfCont != 0:\n",
    "            normalizedContData = self.firstBnLayer(contData)\n",
    "\n",
    "            if self.noOfEmbs != 0:\n",
    "                x = torch.cat([x, normalizedContData], 1) \n",
    "            else:\n",
    "                x = normalizedContData\n",
    "\n",
    "        for linLayer, dropoutLayer, bnLayer in\\\n",
    "            zip(self.linLayers, self.droputLayers, self.bnLayers):\n",
    "\n",
    "            x = F.relu(linLayer(x))\n",
    "            x = bnLayer(x)\n",
    "            x = dropoutLayer(x)\n",
    "\n",
    "        x = self.outputLayer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('.datasets/train.csv', usecols=[\"SalePrice\", \"MSSubClass\", \"MSZoning\", \"LotFrontage\", \"LotArea\",\n",
    "                                                  \"Street\", \"YearBuilt\", \"LotShape\", \"1stFlrSF\", \"2ndFlrSF\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalFeatures = [\"MSSubClass\", \"MSZoning\", \"Street\", \"LotShape\", \"YearBuilt\"]\n",
    "outputFeature = \"SalePrice\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoders = {}\n",
    "for catCol in categoricalFeatures:\n",
    "    labelEncoders[catCol] = LabelEncoder()\n",
    "    data[catCol] = labelEncoders[catCol].fit_transform(data[catCol])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TabularDataset(data=data, catCols=categoricalFeatures, outputCol=outputFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "dataLoader = DataLoader(dataset, bs, shuffle=True, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catDims = [int(data[col].nunique()) for col in categoricalFeatures]\n",
    "catDims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embDims = [(x, min(50, (x+1) // 2)) for x in catDims]\n",
    "embDims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeedForwardNN(embDims, noOfCont=4, linLayerSizes=[50, 100], \n",
    "                      outputSize=1, embDropout=0.04, linLayerDropouts=[0.001, 0.01]).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for y, contX, catX in dataLoader:\n",
    "          \n",
    "        catX = catX.to(device)\n",
    "        contX = contX.to(device)\n",
    "        y  = y.to(device)\n",
    "\n",
    "        # Forward Pass\n",
    "        preds = model(contX, catX)\n",
    "        loss = criterion(preds, y)\n",
    "\n",
    "        # Backward Pass and Optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "           \n",
    "    print ('Epoch [{}/{}], Loss: {}'\n",
    "            .format(epoch+1, epochs, loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
