{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "trainDs = datasets.MNIST(root='./.data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "testDs = datasets.MNIST(root='./.data', train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 100\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the dataset iterable\n",
    "trainLoader = torch.utils.data.DataLoader(dataset = trainDs, batch_size = batchSize, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(dataset = testDs, batch_size = batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 60000 images in the training set\n",
      "There are 10000 images in the test set\n",
      "There are 600 batches in the train loader\n",
      "There are 100 batches in the testloader\n"
     ]
    }
   ],
   "source": [
    "print('There are {} images in the training set'.format(len(trainDs)))\n",
    "print('There are {} images in the test set'.format(len(testDs)))\n",
    "print('There are {} batches in the train loader'.format(len(trainLoader)))\n",
    "print('There are {} batches in the testloader'.format(len(testLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #Same Padding = [(filter size - 1) / 2] (Same Padding--> input size = output size)\n",
    "        # input_channel is one because the images are b&w, out=8 is an arbitrary number\n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3,stride=1, padding=1)\n",
    "        #The output size of each of the 8 feature maps is \n",
    "        #[(input_size - filter_size + 2(padding) / stride) +1] --> [(28-3+2(1)/1)+1] = 28 (padding type is same)\n",
    "        #Batch normalization\n",
    "        self.batchnorm1 = nn.BatchNorm2d(8)\n",
    "        #RELU\n",
    "        self.relu = nn.ReLU()\n",
    "        #Max poolin\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        #After max pooling, the output of each feature map is now 28/2 = 14\n",
    "        self.cnn2 = nn.Conv2d(in_channels=8, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        #Output size of each of the 32 feature maps remains 14\n",
    "        self.batchnorm2 = nn.BatchNorm2d(32)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        #After max pooling, the output of each feature map is 14/2 = 7\n",
    "        #Flatten the feature maps. You have 32 feature maps, each of them is of size 7x7 --> 32*7*7 = 1568\n",
    "        self.fc1 = nn.Linear(in_features=1568, out_features=600)\n",
    "        self.droput = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(in_features=600, out_features=10) #out is the num of classses we have\n",
    "    def forward(self,x):\n",
    "        out = self.cnn1(x)\n",
    "        out = self.batchnorm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.cnn2(out)\n",
    "        out = self.batchnorm2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool2(out)\n",
    "        #Now we have to flatten the output. This is where we apply the feed forward neural network as learned before! \n",
    "        #It will take the shape (batch_size, 1568) = (100, 1568)\n",
    "        out = out.view(-1,1568)\n",
    "        #Then we forward through our fully connected layer \n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.droput(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "else:\n",
    "    print('CUDA is not available')\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, Training Loss: 1.28413975239, Test Accuracy: 76%\n",
      "Iteration 200, Training Loss: 0.636543154716, Test Accuracy: 83%\n",
      "Iteration 300, Training Loss: 0.562572360039, Test Accuracy: 86%\n",
      "Iteration 400, Training Loss: 0.35500022769, Test Accuracy: 84%\n",
      "Iteration 500, Training Loss: 0.329743921757, Test Accuracy: 89%\n",
      "Iteration 600, Training Loss: 0.278683722019, Test Accuracy: 89%\n",
      "Iteration 700, Training Loss: 0.184824258089, Test Accuracy: 94%\n",
      "Iteration 800, Training Loss: 0.335571944714, Test Accuracy: 93%\n",
      "Iteration 900, Training Loss: 0.248443931341, Test Accuracy: 91%\n",
      "Iteration 1000, Training Loss: 0.219458043575, Test Accuracy: 93%\n",
      "Iteration 1100, Training Loss: 0.266739606857, Test Accuracy: 94%\n",
      "Iteration 1200, Training Loss: 0.202846392989, Test Accuracy: 95%\n",
      "Iteration 1300, Training Loss: 0.0656813308597, Test Accuracy: 94%\n",
      "Iteration 1400, Training Loss: 0.161116108298, Test Accuracy: 94%\n",
      "Iteration 1500, Training Loss: 0.0507277213037, Test Accuracy: 97%\n",
      "Iteration 1600, Training Loss: 0.0679155066609, Test Accuracy: 95%\n",
      "Iteration 1700, Training Loss: 0.192957311869, Test Accuracy: 97%\n",
      "Iteration 1800, Training Loss: 0.0654500201344, Test Accuracy: 96%\n",
      "Iteration 1900, Training Loss: 0.121920794249, Test Accuracy: 96%\n",
      "Iteration 2000, Training Loss: 0.0859093740582, Test Accuracy: 96%\n",
      "Iteration 2100, Training Loss: 0.0618892759085, Test Accuracy: 97%\n",
      "Iteration 2200, Training Loss: 0.0557825565338, Test Accuracy: 96%\n",
      "Iteration 2300, Training Loss: 0.151362553239, Test Accuracy: 97%\n",
      "Iteration 2400, Training Loss: 0.088697090745, Test Accuracy: 96%\n",
      "Iteration 2500, Training Loss: 0.0750499367714, Test Accuracy: 97%\n",
      "Iteration 2600, Training Loss: 0.122241646051, Test Accuracy: 97%\n",
      "Iteration 2700, Training Loss: 0.0759573280811, Test Accuracy: 98%\n",
      "Iteration 2800, Training Loss: 0.157690122724, Test Accuracy: 97%\n",
      "Iteration 2900, Training Loss: 0.0964407920837, Test Accuracy: 97%\n",
      "Iteration 3000, Training Loss: 0.118679597974, Test Accuracy: 98%\n",
      "Iteration 3100, Training Loss: 0.111438073218, Test Accuracy: 98%\n",
      "Iteration 3200, Training Loss: 0.0342076532543, Test Accuracy: 96%\n",
      "Iteration 3300, Training Loss: 0.0520122908056, Test Accuracy: 96%\n",
      "Iteration 3400, Training Loss: 0.137401774526, Test Accuracy: 98%\n",
      "Iteration 3500, Training Loss: 0.0767472013831, Test Accuracy: 98%\n",
      "Iteration 3600, Training Loss: 0.0870079025626, Test Accuracy: 98%\n",
      "Iteration 3700, Training Loss: 0.0474537163973, Test Accuracy: 98%\n",
      "Iteration 3800, Training Loss: 0.0972476452589, Test Accuracy: 97%\n",
      "Iteration 3900, Training Loss: 0.116405598819, Test Accuracy: 96%\n",
      "Iteration 4000, Training Loss: 0.093065738678, Test Accuracy: 97%\n",
      "Iteration 4100, Training Loss: 0.0849367156625, Test Accuracy: 98%\n",
      "Iteration 4200, Training Loss: 0.0605181492865, Test Accuracy: 97%\n",
      "Iteration 4300, Training Loss: 0.0646939203143, Test Accuracy: 98%\n",
      "Iteration 4400, Training Loss: 0.0630602389574, Test Accuracy: 98%\n",
      "Iteration 4500, Training Loss: 0.0674346908927, Test Accuracy: 96%\n",
      "Iteration 4600, Training Loss: 0.104027248919, Test Accuracy: 99%\n",
      "Iteration 4700, Training Loss: 0.0809200853109, Test Accuracy: 99%\n",
      "Iteration 4800, Training Loss: 0.0420456975698, Test Accuracy: 98%\n",
      "Iteration 4900, Training Loss: 0.0810727998614, Test Accuracy: 97%\n",
      "Iteration 5000, Training Loss: 0.0965241789818, Test Accuracy: 97%\n",
      "Iteration 5100, Training Loss: 0.066530354321, Test Accuracy: 98%\n",
      "Iteration 5200, Training Loss: 0.0756630823016, Test Accuracy: 97%\n",
      "Iteration 5300, Training Loss: 0.0527659766376, Test Accuracy: 99%\n",
      "Iteration 5400, Training Loss: 0.0181196946651, Test Accuracy: 98%\n",
      "Iteration 5500, Training Loss: 0.0821612849832, Test Accuracy: 97%\n",
      "Iteration 5600, Training Loss: 0.187507405877, Test Accuracy: 99%\n",
      "Iteration 5700, Training Loss: 0.106689825654, Test Accuracy: 99%\n",
      "Iteration 5800, Training Loss: 0.0357733517885, Test Accuracy: 97%\n",
      "Iteration 5900, Training Loss: 0.0656071528792, Test Accuracy: 99%\n",
      "Iteration 6000, Training Loss: 0.0590418949723, Test Accuracy: 99%\n",
      "TRAINING DONE!\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(trainLoader):\n",
    "        iter += 1\n",
    "        if CUDA:\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = lossFunction(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Test the model every 100 iterarion, Calculate and print the testing accuracy\n",
    "        if (i+1) % 100 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in testLoader:\n",
    "                if CUDA:\n",
    "                    images = Variable(images.cuda())\n",
    "                else:\n",
    "                    images = Variable(images)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            if CUDA:\n",
    "                correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "            else:\n",
    "                correct += (predicted == labels).sum()\n",
    "                \n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration {}, Training Loss: {}, Test Accuracy: {}%'.format(iter, loss.item(), accuracy))\n",
    "print(\"TRAINING DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
